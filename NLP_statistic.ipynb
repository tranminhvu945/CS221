{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531bae65",
   "metadata": {},
   "source": [
    "# Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aaafc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./Data/Original/ViCTSD_train.csv\")\n",
    "val = pd.read_csv(\"./Data/Original/ViCTSD_valid.csv\")\n",
    "test = pd.read_csv(\"./Data/Original/ViCTSD_test.csv\")\n",
    "data = pd.concat([train, val, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3d14826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['Comment', 'Constructiveness']]\n",
    "val = val[['Comment', 'Constructiveness']]\n",
    "test = test[['Comment', 'Constructiveness']]\n",
    "data = data[['Comment', 'Constructiveness']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2b3a4a",
   "metadata": {},
   "source": [
    "# Định nghĩa thống kê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5268bdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_stats(text_series):\n",
    "    all_tokens = [str(text).split() for text in text_series]\n",
    "    \n",
    "    lengths = [len(tokens) for tokens in all_tokens]\n",
    "    avg_len = np.mean(lengths)\n",
    "    \n",
    "    flat_tokens = [word.lower() for tokens in all_tokens for word in tokens]\n",
    "    vocab_size = len(set(flat_tokens))\n",
    "    \n",
    "    return avg_len, vocab_size, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9a0e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sentiment_distribution(df, title_suffix=\"\"):\n",
    "    text_col = 'Comment' # Tên cột text của bạn\n",
    "    # Chuyển sang dạng dọc để đếm\n",
    "    sentiment_order = ['Constructiveness', 'Non-Constructiveness']\n",
    "    \n",
    "    # Vẽ countplot\n",
    "    ax = sns.countplot(data=df,\n",
    "                       order=sentiment_order, \n",
    "                       palette='coolwarm')\n",
    "    \n",
    "    # Thêm số liệu trên đầu cột (như code bạn yêu cầu)\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, padding=3, fontsize=10) \n",
    "\n",
    "    # Trang trí\n",
    "    plt.title(f'Sentiment Distribution of {title_suffix}', fontsize=14)\n",
    "    \n",
    "    if not df.empty:\n",
    "        plt.ylim(0, df['Polarity'].value_counts().max() * 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815b6425",
   "metadata": {},
   "source": [
    "# Thống kê"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d380dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Avg. Length: 29.38\n",
      "2. Vocab Size: 17945\n",
      "\n",
      "1. Avg. Length Train: 29.22\n",
      "2. Vocab Size: 14410\n",
      "\n",
      "1. Avg. Length Val: 30.19\n",
      "2. Vocab Size: 7399\n",
      "\n",
      "1. Avg. Length Test: 28.92\n",
      "2. Vocab Size: 4581\n"
     ]
    }
   ],
   "source": [
    "avg_len, vocab_size, lengths = get_text_stats(data['Comment'])\n",
    "print(f\"1. Avg. Length: {avg_len:.2f}\")\n",
    "print(f\"2. Vocab Size: {vocab_size}\")\n",
    "print()\n",
    "\n",
    "avg_len, vocab_size, lengths = get_text_stats(train['Comment'])\n",
    "print(f\"1. Avg. Length Train: {avg_len:.2f}\")\n",
    "print(f\"2. Vocab Size: {vocab_size}\")\n",
    "print()\n",
    "\n",
    "avg_len, vocab_size, lengths = get_text_stats(val['Comment'])\n",
    "print(f\"1. Avg. Length Val: {avg_len:.2f}\")\n",
    "print(f\"2. Vocab Size: {vocab_size}\")\n",
    "print()\n",
    "\n",
    "avg_len, vocab_size, lengths = get_text_stats(test['Comment'])\n",
    "print(f\"1. Avg. Length Test: {avg_len:.2f}\")\n",
    "print(f\"2. Vocab Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79840968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số lượng Vocab trong tập Train: 14410\n",
      "No. words in Val not in Train set: 2535\n",
      "No. words in Test not in Train set: 1101\n"
     ]
    }
   ],
   "source": [
    "column_name = 'Comment'  \n",
    "\n",
    "def get_vocab_set(df, col):\n",
    "    vocab = set()\n",
    "    for text in df[col].astype(str):\n",
    "        words = text.lower().split() \n",
    "        vocab.update(words)\n",
    "    return vocab\n",
    "\n",
    "vocab_train = get_vocab_set(train, column_name)\n",
    "vocab_val = get_vocab_set(val, column_name)\n",
    "vocab_test = get_vocab_set(test, column_name)\n",
    "\n",
    "print(f\"Tổng số lượng Vocab trong tập Train: {len(vocab_train)}\")\n",
    "\n",
    "oov_val = vocab_val - vocab_train\n",
    "oov_test = vocab_test - vocab_train\n",
    "\n",
    "print(f\"No. words in Val not in Train set: {len(oov_val)}\")\n",
    "print(f\"No. words in Test not in Train set: {len(oov_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
