{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcff3317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84abc3b3",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b901a98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./Data/Preprocessed/ViCTSD_train-clean.csv\")\n",
    "val = pd.read_csv(\"./Data/Preprocessed/ViCTSD_valid-clean.csv\")\n",
    "test = pd.read_csv(\"./Data/Preprocessed/ViCTSD_test-clean.csv\")\n",
    "\n",
    "X_train = train['Comment_clean'].tolist()\n",
    "y_train = train['Constructiveness']\n",
    "\n",
    "X_val = val['Comment_clean'].tolist()\n",
    "y_val = val['Constructiveness']\n",
    "\n",
    "X_test = test['Comment_clean'].tolist()\n",
    "y_test = test['Constructiveness']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e8d57d",
   "metadata": {},
   "source": [
    "# **Machine Learning Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195af192",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2140a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=2, max_df=0.9)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = vectorizer.transform(X_val)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a8afb",
   "metadata": {},
   "source": [
    "## PhoW2V Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2f3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phow2v = pd.read_csv('./Data/Embedding/ViCTSD_train-phoW2V.csv')\n",
    "val_phow2v = pd.read_csv('./Data/Embedding/ViCTSD_val-phoW2V.csv')\n",
    "test_phow2v = pd.read_csv('./Data/Embedding/ViCTSD_test-phoW2V.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e1e9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_phow2v = train_phow2v.iloc[:, :100]\n",
    "X_val_phow2v = val_phow2v.iloc[:, :100]\n",
    "X_test_phow2v = test_phow2v.iloc[:, :100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf28ec1",
   "metadata": {},
   "source": [
    "## Search Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c88bc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\DS102\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ab83884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(study, trial):\n",
    "    if study.best_trial.number == trial.number:\n",
    "        study.set_user_attr(key='best_model', value=trial.user_attrs['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c672b5",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44f8e1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e63042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c542bf23",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:27:05,943] A new study created in memory with name: no-name-0dd9377a-029b-4fa8-b11c-efff62d88bd0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:27:06,195] Trial 0 finished with value: 0.7088255733148019 and parameters: {'class_weight': None, 'C': 8.41076650090714}. Best is trial 0 with value: 0.7088255733148019.\n",
      "[I 2025-12-22 10:27:06,266] Trial 1 finished with value: 0.7113665389527458 and parameters: {'class_weight': 'balanced', 'C': 6.777285823434402}. Best is trial 1 with value: 0.7113665389527458.\n",
      "[I 2025-12-22 10:27:06,567] Trial 2 finished with value: 0.7001414427157001 and parameters: {'class_weight': None, 'C': 4.408098128709346}. Best is trial 1 with value: 0.7113665389527458.\n",
      "[I 2025-12-22 10:27:06,688] Trial 3 finished with value: 0.7092198581560284 and parameters: {'class_weight': 'balanced', 'C': 11.224078321223027}. Best is trial 1 with value: 0.7113665389527458.\n",
      "[I 2025-12-22 10:27:06,789] Trial 4 finished with value: 0.7130214917825537 and parameters: {'class_weight': 'balanced', 'C': 3.7822352140976876}. Best is trial 4 with value: 0.7130214917825537.\n",
      "[I 2025-12-22 10:27:07,069] Trial 5 finished with value: 0.7118175535590877 and parameters: {'class_weight': None, 'C': 19.156643783543824}. Best is trial 4 with value: 0.7130214917825537.\n",
      "[I 2025-12-22 10:27:07,165] Trial 6 finished with value: 0.7175177763413058 and parameters: {'class_weight': 'balanced', 'C': 15.3598571591844}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:07,229] Trial 7 finished with value: 0.7116249197174053 and parameters: {'class_weight': 'balanced', 'C': 12.304120349802874}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:07,464] Trial 8 finished with value: 0.7090532135452661 and parameters: {'class_weight': None, 'C': 14.05271335095385}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:07,715] Trial 9 finished with value: 0.7136929460580913 and parameters: {'class_weight': None, 'C': 19.777725588403577}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:07,820] Trial 10 finished with value: 0.7153945666235446 and parameters: {'class_weight': 'balanced', 'C': 15.573848320702922}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:07,965] Trial 11 finished with value: 0.7162426614481409 and parameters: {'class_weight': 'balanced', 'C': 16.66281895595293}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:08,105] Trial 12 finished with value: 0.712987012987013 and parameters: {'class_weight': 'balanced', 'C': 16.347919321575453}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:08,230] Trial 13 finished with value: 0.7153094462540717 and parameters: {'class_weight': 'balanced', 'C': 17.241676215513685}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:08,291] Trial 14 finished with value: 0.6987218502738892 and parameters: {'class_weight': 'balanced', 'C': 0.3089718596821598}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:08,424] Trial 15 finished with value: 0.7124352331606217 and parameters: {'class_weight': 'balanced', 'C': 13.553850785646084}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:08,572] Trial 16 finished with value: 0.7131782945736435 and parameters: {'class_weight': 'balanced', 'C': 10.310326818054111}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:08,676] Trial 17 finished with value: 0.7151200519143414 and parameters: {'class_weight': 'balanced', 'C': 17.594256714915414}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:08,791] Trial 18 finished with value: 0.7134502923976608 and parameters: {'class_weight': 'balanced', 'C': 14.1683265230075}. Best is trial 6 with value: 0.7175177763413058.\n",
      "[I 2025-12-22 10:27:08,882] Trial 19 finished with value: 0.7179818887451488 and parameters: {'class_weight': 'balanced', 'C': 15.423831970037199}. Best is trial 19 with value: 0.7179818887451488.\n"
     ]
    }
   ],
   "source": [
    "def logistic_objective(trial):\n",
    "    params = dict(\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        C=trial.suggest_float('C', 1e-5, 20),\n",
    "        random_state=42,\n",
    "        max_iter=200\n",
    "    )    \n",
    "\n",
    "    clf = LogisticRegression(**params)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "logistic_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "logistic_study.optimize(logistic_objective, n_trials=20, callbacks=[callback])\n",
    "\n",
    "lgr = logistic_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c3ca1a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Best Hyperparameters F1-scores:\n",
      "train: 0.9973599930552288\n",
      "val:   0.7701563885453535\n",
      "val:                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82      1271\n",
      "           1       0.68      0.76      0.72       729\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.77      0.78      0.77      2000\n",
      "weighted avg       0.79      0.78      0.78      2000\n",
      "\n",
      "test:  0.78658855528821\n",
      "test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83       636\n",
      "           1       0.69      0.80      0.74       364\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.78      0.80      0.79      1000\n",
      "weighted avg       0.81      0.80      0.80      1000\n",
      "\n",
      "{'C': 15.423831970037199, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 200, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'class_weight': 'balanced', 'C': 15.423831970037199}\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with Best Hyperparameters F1-scores:\")\n",
    "print('train:', f1_score(y_train, lgr.predict(X_train_tfidf), average='macro'))\n",
    "print('val:  ', f1_score(y_val  , lgr.predict(X_val_tfidf), average='macro'))\n",
    "print('val:  ', classification_report(y_val  , lgr.predict(X_val_tfidf)))\n",
    "print('test: ', f1_score(y_test , lgr.predict(X_test_tfidf), average='macro'))\n",
    "print('test: ', classification_report(y_test , lgr.predict(X_test_tfidf)))\n",
    "\n",
    "print(lgr.get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(logistic_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cfe664",
   "metadata": {},
   "source": [
    "### PhoW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e598b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:31:24,189] A new study created in memory with name: no-name-63163a58-d55d-4c08-9b42-5bc78601aeb4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:31:24,279] Trial 0 finished with value: 0.5197472353870458 and parameters: {'class_weight': None, 'C': 8.41076650090714}. Best is trial 0 with value: 0.5197472353870458.\n",
      "[I 2025-12-22 10:31:24,354] Trial 1 finished with value: 0.6190754827384435 and parameters: {'class_weight': 'balanced', 'C': 6.777285823434402}. Best is trial 1 with value: 0.6190754827384435.\n",
      "[I 2025-12-22 10:31:24,389] Trial 2 finished with value: 0.5231259968102073 and parameters: {'class_weight': None, 'C': 4.408098128709346}. Best is trial 1 with value: 0.6190754827384435.\n",
      "[I 2025-12-22 10:31:24,449] Trial 3 finished with value: 0.6206896551724138 and parameters: {'class_weight': 'balanced', 'C': 11.224078321223027}. Best is trial 3 with value: 0.6206896551724138.\n",
      "[I 2025-12-22 10:31:24,502] Trial 4 finished with value: 0.6194073213248111 and parameters: {'class_weight': 'balanced', 'C': 3.7822352140976876}. Best is trial 3 with value: 0.6206896551724138.\n",
      "[I 2025-12-22 10:31:24,583] Trial 5 finished with value: 0.5268901013250195 and parameters: {'class_weight': None, 'C': 19.156643783543824}. Best is trial 3 with value: 0.6206896551724138.\n",
      "[I 2025-12-22 10:31:24,634] Trial 6 finished with value: 0.6209724663151728 and parameters: {'class_weight': 'balanced', 'C': 15.3598571591844}. Best is trial 6 with value: 0.6209724663151728.\n",
      "[I 2025-12-22 10:31:24,673] Trial 7 finished with value: 0.624561403508772 and parameters: {'class_weight': 'balanced', 'C': 12.304120349802874}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:24,724] Trial 8 finished with value: 0.5261514441842311 and parameters: {'class_weight': None, 'C': 14.05271335095385}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:24,774] Trial 9 finished with value: 0.5263157894736842 and parameters: {'class_weight': None, 'C': 19.777725588403577}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:24,804] Trial 10 finished with value: 0.6089965397923875 and parameters: {'class_weight': 'balanced', 'C': 0.6571604653216117}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:24,875] Trial 11 finished with value: 0.6206088992974239 and parameters: {'class_weight': 'balanced', 'C': 14.627260532249437}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:24,925] Trial 12 finished with value: 0.619800820152314 and parameters: {'class_weight': 'balanced', 'C': 14.98806047130978}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:24,983] Trial 13 finished with value: 0.6206088992974239 and parameters: {'class_weight': 'balanced', 'C': 11.769069901268109}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:25,029] Trial 14 finished with value: 0.623391812865497 and parameters: {'class_weight': 'balanced', 'C': 16.818419725084524}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:25,074] Trial 15 finished with value: 0.6241217798594848 and parameters: {'class_weight': 'balanced', 'C': 17.439114979459166}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:25,143] Trial 16 finished with value: 0.6205278592375366 and parameters: {'class_weight': 'balanced', 'C': 17.677146177926158}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:25,196] Trial 17 finished with value: 0.6186291739894552 and parameters: {'class_weight': 'balanced', 'C': 12.952575972732868}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:25,246] Trial 18 finished with value: 0.6237565827969573 and parameters: {'class_weight': 'balanced', 'C': 9.39051405858672}. Best is trial 7 with value: 0.624561403508772.\n",
      "[I 2025-12-22 10:31:25,297] Trial 19 finished with value: 0.6209724663151728 and parameters: {'class_weight': 'balanced', 'C': 17.835394651437397}. Best is trial 7 with value: 0.624561403508772.\n"
     ]
    }
   ],
   "source": [
    "def logistic_objective(trial):\n",
    "    params = dict(\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        C=trial.suggest_float('C', 1e-5, 20),\n",
    "        random_state=42,\n",
    "        max_iter=200\n",
    "    )    \n",
    "\n",
    "    clf = LogisticRegression(**params)\n",
    "    clf.fit(X_train_phow2v, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_phow2v)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "logistic_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "logistic_study.optimize(logistic_objective, n_trials=20, callbacks=[callback])\n",
    "\n",
    "lgr = logistic_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e598180e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with Best Hyperparameters F1-scores:\n",
      "train: 0.6924891327619445\n",
      "val:   0.6721060292653029\n",
      "val:                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72      1271\n",
      "           1       0.54      0.73      0.62       729\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.68      0.69      0.67      2000\n",
      "weighted avg       0.71      0.68      0.68      2000\n",
      "\n",
      "test:  0.6722265242490915\n",
      "test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.66      0.72       636\n",
      "           1       0.55      0.72      0.62       364\n",
      "\n",
      "    accuracy                           0.68      1000\n",
      "   macro avg       0.68      0.69      0.67      1000\n",
      "weighted avg       0.71      0.68      0.69      1000\n",
      "\n",
      "{'C': 12.304120349802874, 'class_weight': 'balanced', 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 200, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': 42, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'class_weight': 'balanced', 'C': 12.304120349802874}\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression with Best Hyperparameters F1-scores:\")\n",
    "print('train:', f1_score(y_train, lgr.predict(X_train_phow2v), average='macro'))\n",
    "print('val:  ', f1_score(y_val  , lgr.predict(X_val_phow2v), average='macro'))\n",
    "print('val:  ', classification_report(y_val  , lgr.predict(X_val_phow2v)))\n",
    "print('test: ', f1_score(y_test , lgr.predict(X_test_phow2v), average='macro'))\n",
    "print('test: ', classification_report(y_test , lgr.predict(X_test_phow2v)))\n",
    "\n",
    "print(lgr.get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(logistic_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3fe96e",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33a3822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c38ac9",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0463f398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:33:31,231] A new study created in memory with name: no-name-6e760abd-5fb3-4492-8b5c-f6c497ca44e2\n",
      "[I 2025-12-22 10:33:31,255] Trial 0 finished with value: 0.5721021611001965 and parameters: {'C': 1.9636582699290402e-07, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 0 with value: 0.5721021611001965.\n",
      "[I 2025-12-22 10:33:31,268] Trial 1 finished with value: 0.0 and parameters: {'C': 5.339536586472381e-06, 'class_weight': None, 'loss': 'squared_hinge'}. Best is trial 0 with value: 0.5721021611001965.\n",
      "[I 2025-12-22 10:33:31,277] Trial 2 finished with value: 0.0 and parameters: {'C': 1.3055563380836963e-09, 'class_weight': None, 'loss': 'hinge'}. Best is trial 0 with value: 0.5721021611001965.\n",
      "[I 2025-12-22 10:33:31,288] Trial 3 finished with value: 0.0 and parameters: {'C': 1.1682869614143264e-09, 'class_weight': None, 'loss': 'hinge'}. Best is trial 0 with value: 0.5721021611001965.\n",
      "[I 2025-12-22 10:33:31,304] Trial 4 finished with value: 0.7052307692307692 and parameters: {'C': 0.2804917948703948, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 4 with value: 0.7052307692307692.\n",
      "[I 2025-12-22 10:33:31,319] Trial 5 finished with value: 0.6749262536873156 and parameters: {'C': 0.002674151911363306, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.7052307692307692.\n",
      "[I 2025-12-22 10:33:31,336] Trial 6 finished with value: 0.6979293544457978 and parameters: {'C': 0.02828254640470946, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.7052307692307692.\n",
      "[I 2025-12-22 10:33:31,357] Trial 7 finished with value: 0.7138384470882906 and parameters: {'C': 0.15640579894830894, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 7 with value: 0.7138384470882906.\n",
      "[I 2025-12-22 10:33:31,368] Trial 8 finished with value: 0.0 and parameters: {'C': 2.6540634283127564e-06, 'class_weight': None, 'loss': 'hinge'}. Best is trial 7 with value: 0.7138384470882906.\n",
      "[I 2025-12-22 10:33:31,386] Trial 9 finished with value: 0.6983546617915904 and parameters: {'C': 0.03412839819879307, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 7 with value: 0.7138384470882906.\n",
      "[I 2025-12-22 10:33:32,611] Trial 10 finished with value: 0.692722371967655 and parameters: {'C': 78.77092791878185, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 7 with value: 0.7138384470882906.\n",
      "[I 2025-12-22 10:33:32,685] Trial 11 finished with value: 0.6926698049764627 and parameters: {'C': 5.974855701699721, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 7 with value: 0.7138384470882906.\n",
      "[I 2025-12-22 10:33:32,708] Trial 12 finished with value: 0.7097966728280961 and parameters: {'C': 0.3122532064423227, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 7 with value: 0.7138384470882906.\n",
      "[I 2025-12-22 10:33:32,752] Trial 13 finished with value: 0.7154046997389034 and parameters: {'C': 1.321090493383731, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 13 with value: 0.7154046997389034.\n",
      "[I 2025-12-22 10:33:32,766] Trial 14 finished with value: 0.6641468682505399 and parameters: {'C': 0.0003433735485076392, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 13 with value: 0.7154046997389034.\n",
      "[I 2025-12-22 10:33:32,884] Trial 15 finished with value: 0.6942590120160214 and parameters: {'C': 6.70298473602607, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 13 with value: 0.7154046997389034.\n",
      "[I 2025-12-22 10:33:32,960] Trial 16 finished with value: 0.7007299270072993 and parameters: {'C': 3.3309389957189524, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 13 with value: 0.7154046997389034.\n",
      "[I 2025-12-22 10:33:32,977] Trial 17 finished with value: 0.6769779892920881 and parameters: {'C': 0.00410443480690731, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 13 with value: 0.7154046997389034.\n",
      "[I 2025-12-22 10:33:34,309] Trial 18 finished with value: 0.6931894807821982 and parameters: {'C': 83.93966822473341, 'class_weight': None, 'loss': 'squared_hinge'}. Best is trial 13 with value: 0.7154046997389034.\n",
      "[I 2025-12-22 10:33:34,336] Trial 19 finished with value: 0.7165504121750158 and parameters: {'C': 0.35855697016049437, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 19 with value: 0.7165504121750158.\n"
     ]
    }
   ],
   "source": [
    "def linearsvc_objective(trial):\n",
    "    params = dict(\n",
    "        C=trial.suggest_float('C', 1e-9, 1e2, log=True),\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        loss=trial.suggest_categorical('loss', ['hinge', 'squared_hinge']),\n",
    "        max_iter=10000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    if params['loss'] == 'hinge':\n",
    "        params['dual'] = True\n",
    "    clf = (LinearSVC(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "    \n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "svc_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "svc_study.optimize(linearsvc_objective, n_trials=20, callbacks=[callback])\n",
    "\n",
    "svc_linear = svc_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6404d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC with Best Hyperparameters F1-scores:\n",
      "train: 0.9726172502532795\n",
      "val:   0.7660341825629515\n",
      "val:                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      1271\n",
      "           1       0.67      0.78      0.72       729\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.76      0.78      0.77      2000\n",
      "weighted avg       0.79      0.78      0.78      2000\n",
      "\n",
      "test:  0.7824744873648752\n",
      "test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.77      0.82       636\n",
      "           1       0.67      0.83      0.74       364\n",
      "\n",
      "    accuracy                           0.79      1000\n",
      "   macro avg       0.78      0.80      0.78      1000\n",
      "weighted avg       0.81      0.79      0.79      1000\n",
      "\n",
      "{'C': 0.35855697016049437, 'class_weight': 'balanced', 'dual': 'auto', 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'squared_hinge', 'max_iter': 10000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'C': 0.35855697016049437, 'class_weight': 'balanced', 'loss': 'squared_hinge'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVC with Best Hyperparameters F1-scores:\")\n",
    "print('train:', f1_score(y_train, svc_linear.predict(X_train_tfidf), average='macro'))\n",
    "print('val:  ', f1_score(y_val  , svc_linear.predict(X_val_tfidf), average='macro'))\n",
    "print('val:  ', classification_report(y_val  , svc_linear.predict(X_val_tfidf)))\n",
    "print('test: ', f1_score(y_test , svc_linear.predict(X_test_tfidf), average='macro'))\n",
    "print('test: ', classification_report(y_test , svc_linear.predict(X_test_tfidf)))\n",
    "\n",
    "print(svc_linear.get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(svc_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfb0fe",
   "metadata": {},
   "source": [
    "### PhoW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3926e12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:34:44,882] A new study created in memory with name: no-name-fb4175e5-bdbc-4c2c-9eea-343049af156a\n",
      "[I 2025-12-22 10:34:44,916] Trial 0 finished with value: 0.5580322828593389 and parameters: {'C': 1.9636582699290402e-07, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 0 with value: 0.5580322828593389.\n",
      "[I 2025-12-22 10:34:44,956] Trial 1 finished with value: 0.0 and parameters: {'C': 5.339536586472381e-06, 'class_weight': None, 'loss': 'squared_hinge'}. Best is trial 0 with value: 0.5580322828593389.\n",
      "[I 2025-12-22 10:34:44,976] Trial 2 finished with value: 0.0 and parameters: {'C': 1.3055563380836963e-09, 'class_weight': None, 'loss': 'hinge'}. Best is trial 0 with value: 0.5580322828593389.\n",
      "[I 2025-12-22 10:34:44,998] Trial 3 finished with value: 0.0 and parameters: {'C': 1.1682869614143264e-09, 'class_weight': None, 'loss': 'hinge'}. Best is trial 0 with value: 0.5580322828593389.\n",
      "[I 2025-12-22 10:34:45,070] Trial 4 finished with value: 0.6150490730643402 and parameters: {'C': 0.2804917948703948, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 4 with value: 0.6150490730643402.\n",
      "[I 2025-12-22 10:34:45,119] Trial 5 finished with value: 0.5969162995594713 and parameters: {'C': 0.002674151911363306, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.6150490730643402.\n",
      "[I 2025-12-22 10:34:45,186] Trial 6 finished with value: 0.6063708759954494 and parameters: {'C': 0.02828254640470946, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.6150490730643402.\n",
      "[I 2025-12-22 10:34:45,279] Trial 7 finished with value: 0.6139642238892095 and parameters: {'C': 0.15640579894830894, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.6150490730643402.\n",
      "[I 2025-12-22 10:34:45,302] Trial 8 finished with value: 0.0 and parameters: {'C': 2.6540634283127564e-06, 'class_weight': None, 'loss': 'hinge'}. Best is trial 4 with value: 0.6150490730643402.\n",
      "[I 2025-12-22 10:34:45,383] Trial 9 finished with value: 0.6096866096866097 and parameters: {'C': 0.03412839819879307, 'class_weight': 'balanced', 'loss': 'squared_hinge'}. Best is trial 4 with value: 0.6150490730643402.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:34:47,946] Trial 10 finished with value: 0.6300448430493274 and parameters: {'C': 80.12422295059812, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:34:50,704] Trial 11 finished with value: 0.6299831555306008 and parameters: {'C': 96.34746286467382, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:34:53,415] Trial 12 finished with value: 0.6285714285714286 and parameters: {'C': 87.24201848249336, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:34:56,229] Trial 13 finished with value: 0.6296296296296297 and parameters: {'C': 92.27048191868639, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "[I 2025-12-22 10:34:56,442] Trial 14 finished with value: 0.6202247191011236 and parameters: {'C': 4.631823890613817, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "[I 2025-12-22 10:34:56,594] Trial 15 finished with value: 0.6185682326621924 and parameters: {'C': 2.2535183265850462, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "[I 2025-12-22 10:34:56,992] Trial 16 finished with value: 0.6206509539842873 and parameters: {'C': 5.751773000903087, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "[I 2025-12-22 10:34:57,022] Trial 17 finished with value: 0.5580322828593389 and parameters: {'C': 0.00017330719324443333, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "[I 2025-12-22 10:34:57,057] Trial 18 finished with value: 0.0 and parameters: {'C': 0.0004748395299999667, 'class_weight': None, 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n",
      "[I 2025-12-22 10:34:57,954] Trial 19 finished with value: 0.6292765002804263 and parameters: {'C': 14.845597649626013, 'class_weight': 'balanced', 'loss': 'hinge'}. Best is trial 10 with value: 0.6300448430493274.\n"
     ]
    }
   ],
   "source": [
    "def linearsvc_objective(trial):\n",
    "    params = dict(\n",
    "        C=trial.suggest_float('C', 1e-9, 1e2, log=True),\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        loss=trial.suggest_categorical('loss', ['hinge', 'squared_hinge']),\n",
    "        max_iter=100000,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    if params['loss'] == 'hinge':\n",
    "        params['dual'] = True\n",
    "    clf = (LinearSVC(**params))\n",
    "    clf.fit(X_train_phow2v, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "    \n",
    "    y_pred = clf.predict(X_val_phow2v)\n",
    "    return f1_score(y_val, y_pred)\n",
    "sampler = TPESampler(seed=22)\n",
    "svc_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "svc_study.optimize(linearsvc_objective, n_trials=20, callbacks=[callback])\n",
    "\n",
    "svc_linear = svc_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15023dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC with Best Hyperparameters F1-scores:\n",
      "train: 0.6873688897951102\n",
      "val:   0.6661054540156384\n",
      "val:                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.61      0.70      1271\n",
      "           1       0.53      0.77      0.63       729\n",
      "\n",
      "    accuracy                           0.67      2000\n",
      "   macro avg       0.68      0.69      0.67      2000\n",
      "weighted avg       0.72      0.67      0.68      2000\n",
      "\n",
      "test:  0.6633119556707596\n",
      "test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.62      0.70       636\n",
      "           1       0.53      0.76      0.62       364\n",
      "\n",
      "    accuracy                           0.67      1000\n",
      "   macro avg       0.67      0.69      0.66      1000\n",
      "weighted avg       0.71      0.67      0.67      1000\n",
      "\n",
      "{'C': 80.12422295059812, 'class_weight': 'balanced', 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'loss': 'hinge', 'max_iter': 100000, 'multi_class': 'ovr', 'penalty': 'l2', 'random_state': 42, 'tol': 0.0001, 'verbose': 0}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'C': 80.12422295059812, 'class_weight': 'balanced', 'loss': 'hinge'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Linear SVC with Best Hyperparameters F1-scores:\")\n",
    "print('train:', f1_score(y_train, svc_linear.predict(X_train_phow2v), average='macro'))\n",
    "print('val:  ', f1_score(y_val  , svc_linear.predict(X_val_phow2v), average='macro'))\n",
    "print('val:  ', classification_report(y_val  , svc_linear.predict(X_val_phow2v)))\n",
    "print('test: ', f1_score(y_test , svc_linear.predict(X_test_phow2v), average='macro'))\n",
    "print('test: ', classification_report(y_test , svc_linear.predict(X_test_phow2v)))\n",
    "\n",
    "print(svc_linear.get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(svc_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28969ee8",
   "metadata": {},
   "source": [
    "## Non-Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7caf07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d91e0c",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "036f6e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:35:29,956] A new study created in memory with name: no-name-79293957-96ac-4af2-bb99-c25144a7403d\n",
      "[I 2025-12-22 10:35:40,498] Trial 0 finished with value: 0.0 and parameters: {'kernel': 'poly', 'C': 19.765599562374707, 'gamma': 'auto', 'class_weight': None, 'degree': 2}. Best is trial 0 with value: 0.0.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:35:54,698] Trial 1 finished with value: 0.6992805755395683 and parameters: {'kernel': 'rbf', 'C': 11.71199658483352, 'gamma': 'scale', 'class_weight': None}. Best is trial 1 with value: 0.6992805755395683.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:36:07,456] Trial 2 finished with value: 0.6997840172786177 and parameters: {'kernel': 'rbf', 'C': 6.9177316302209935, 'gamma': 'scale', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6997840172786177.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:36:19,868] Trial 3 finished with value: 0.6120313862249346 and parameters: {'kernel': 'poly', 'C': 41.338016019468874, 'gamma': 'scale', 'class_weight': 'balanced', 'degree': 2}. Best is trial 2 with value: 0.6997840172786177.\n",
      "[I 2025-12-22 10:36:33,376] Trial 4 finished with value: 0.0 and parameters: {'kernel': 'rbf', 'C': 0.0043819711016756845, 'gamma': 'auto', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.6997840172786177.\n"
     ]
    }
   ],
   "source": [
    "def nonlinear_svc_objective(trial):\n",
    "    kernel_choice = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "    \n",
    "    params = dict(\n",
    "        C=trial.suggest_float('C', 1e-3, 100, log=True),\n",
    "        kernel=kernel_choice,\n",
    "        gamma=trial.suggest_categorical('gamma', ['scale', 'auto']), \n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        random_state=42,\n",
    "        max_iter=10000 \n",
    "    )\n",
    "    \n",
    "    if kernel_choice == 'poly':\n",
    "        params['degree'] = trial.suggest_int('degree', 2, 4)\n",
    "\n",
    "    clf = (SVC(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "svc_nonlinear_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "svc_nonlinear_study.optimize(nonlinear_svc_objective, n_trials=5, callbacks=[callback])\n",
    "\n",
    "nonlinear_svc = svc_nonlinear_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b719cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Linear SVC with Best Hyperparameters F1-scores:\n",
      "train: 0.9995337055295797\n",
      "val:   0.7700375467473135\n",
      "val:                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      1271\n",
      "           1       0.74      0.67      0.70       729\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.78      0.76      0.77      2000\n",
      "weighted avg       0.79      0.79      0.79      2000\n",
      "\n",
      "test:  0.790960617196901\n",
      "test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       636\n",
      "           1       0.74      0.73      0.73       364\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.79      0.79      0.79      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n",
      "{'C': 6.9177316302209935, 'break_ties': False, 'cache_size': 200, 'class_weight': 'balanced', 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 10000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'kernel': 'rbf', 'C': 6.9177316302209935, 'gamma': 'scale', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-Linear SVC with Best Hyperparameters F1-scores:\")\n",
    "print('train:', f1_score(y_train, nonlinear_svc.predict(X_train_tfidf), average='macro'))\n",
    "print('val:  ', f1_score(y_val  , nonlinear_svc.predict(X_val_tfidf), average='macro'))\n",
    "print('val:  ', classification_report(y_val  , nonlinear_svc.predict(X_val_tfidf)))\n",
    "print('test: ', f1_score(y_test , nonlinear_svc.predict(X_test_tfidf), average='macro'))\n",
    "print('test: ', classification_report(y_test , nonlinear_svc.predict(X_test_tfidf)))\n",
    "\n",
    "print(nonlinear_svc.get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(svc_nonlinear_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898c2fe",
   "metadata": {},
   "source": [
    "### PhoW2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c67dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:37:21,335] A new study created in memory with name: no-name-0b20271b-b115-4b7e-8ff5-88d8f1cc2749\n",
      "[I 2025-12-22 10:37:23,542] Trial 0 finished with value: 0.0 and parameters: {'kernel': 'poly', 'C': 19.765599562374707, 'gamma': 'auto', 'class_weight': None, 'degree': 2}. Best is trial 0 with value: 0.0.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:37:26,665] Trial 1 finished with value: 0.7051630434782609 and parameters: {'kernel': 'rbf', 'C': 11.71199658483352, 'gamma': 'scale', 'class_weight': None}. Best is trial 1 with value: 0.7051630434782609.\n",
      "[I 2025-12-22 10:37:29,749] Trial 2 finished with value: 0.7100115074798619 and parameters: {'kernel': 'rbf', 'C': 6.9177316302209935, 'gamma': 'scale', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.7100115074798619.\n",
      "d:\\DS102\\venv\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "[I 2025-12-22 10:37:32,341] Trial 3 finished with value: 0.695067264573991 and parameters: {'kernel': 'poly', 'C': 41.338016019468874, 'gamma': 'scale', 'class_weight': 'balanced', 'degree': 2}. Best is trial 2 with value: 0.7100115074798619.\n",
      "[I 2025-12-22 10:37:37,268] Trial 4 finished with value: 0.0 and parameters: {'kernel': 'rbf', 'C': 0.0043819711016756845, 'gamma': 'auto', 'class_weight': 'balanced'}. Best is trial 2 with value: 0.7100115074798619.\n"
     ]
    }
   ],
   "source": [
    "def nonlinear_svc_objective(trial):\n",
    "    kernel_choice = trial.suggest_categorical('kernel', ['rbf', 'poly', 'sigmoid'])\n",
    "    \n",
    "    params = dict(\n",
    "        C=trial.suggest_float('C', 1e-3, 100, log=True),\n",
    "        kernel=kernel_choice,\n",
    "        gamma=trial.suggest_categorical('gamma', ['scale', 'auto']), \n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', None]),\n",
    "        random_state=42,\n",
    "        max_iter=10000 \n",
    "    )\n",
    "    \n",
    "    if kernel_choice == 'poly':\n",
    "        params['degree'] = trial.suggest_int('degree', 2, 4)\n",
    "\n",
    "    clf = (SVC(**params))\n",
    "    clf.fit(X_train_phow2v, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_phow2v)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "svc_nonlinear_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "svc_nonlinear_study.optimize(nonlinear_svc_objective, n_trials=5, callbacks=[callback])\n",
    "\n",
    "nonlinear_svc = svc_nonlinear_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65eeb680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Linear SVC with Best Hyperparameters F1-scores:\n",
      "train: 0.780850815099297\n",
      "val:   0.7435999181961643\n",
      "val:                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.69      0.78      1271\n",
      "           1       0.61      0.85      0.71       729\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.75      0.77      0.74      2000\n",
      "weighted avg       0.79      0.75      0.75      2000\n",
      "\n",
      "test:  0.75506105103303\n",
      "test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.71      0.79       636\n",
      "           1       0.63      0.85      0.72       364\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.76      0.78      0.76      1000\n",
      "weighted avg       0.79      0.76      0.76      1000\n",
      "\n",
      "{'C': 6.9177316302209935, 'break_ties': False, 'cache_size': 200, 'class_weight': 'balanced', 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': 10000, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'kernel': 'rbf', 'C': 6.9177316302209935, 'gamma': 'scale', 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-Linear SVC with Best Hyperparameters F1-scores:\")\n",
    "print('train:', f1_score(y_train, nonlinear_svc.predict(X_train_phow2v), average='macro'))\n",
    "print('val:  ', f1_score(y_val  , nonlinear_svc.predict(X_val_phow2v), average='macro'))\n",
    "print('val:  ', classification_report(y_val  , nonlinear_svc.predict(X_val_phow2v)))\n",
    "print('test: ', f1_score(y_test , nonlinear_svc.predict(X_test_phow2v), average='macro'))\n",
    "print('test: ', classification_report(y_test , nonlinear_svc.predict(X_test_phow2v)))\n",
    "\n",
    "print(nonlinear_svc.get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(svc_nonlinear_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6350482",
   "metadata": {},
   "source": [
    "## MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69173c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f994b27",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc798369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:38:29,921] A new study created in memory with name: no-name-81eaedeb-346b-4927-937f-91004cb50043\n",
      "[I 2025-12-22 10:38:29,941] Trial 0 finished with value: 0.6450809464508095 and parameters: {'alpha': 0.006820907334120959, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:29,955] Trial 1 finished with value: 0.6077998528329654 and parameters: {'alpha': 2.733556118022411, 'fit_prior': False}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:29,990] Trial 2 finished with value: 0.6425855513307985 and parameters: {'alpha': 0.012081791403069187, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:29,999] Trial 3 finished with value: 0.6188466947960619 and parameters: {'alpha': 1.7693089816650007, 'fit_prior': False}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,016] Trial 4 finished with value: 0.46277665995975853 and parameters: {'alpha': 1.7984764264034472, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,027] Trial 5 finished with value: 0.6334639059876889 and parameters: {'alpha': 0.0010581895426425357, 'fit_prior': False}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,035] Trial 6 finished with value: 0.6313065976714101 and parameters: {'alpha': 0.6423201352834903, 'fit_prior': False}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,045] Trial 7 finished with value: 0.6333973128598849 and parameters: {'alpha': 0.5660741193202661, 'fit_prior': False}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,053] Trial 8 finished with value: 0.6384704519119351 and parameters: {'alpha': 0.05131223828514265, 'fit_prior': False}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,062] Trial 9 finished with value: 0.6356502242152466 and parameters: {'alpha': 0.0028027262915760165, 'fit_prior': False}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,072] Trial 10 finished with value: 0.6418786692759295 and parameters: {'alpha': 0.031171718496849413, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,082] Trial 11 finished with value: 0.64375 and parameters: {'alpha': 0.00758910140756327, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,093] Trial 12 finished with value: 0.6433915211970075 and parameters: {'alpha': 0.007208000545856589, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,101] Trial 13 finished with value: 0.6262626262626263 and parameters: {'alpha': 0.154483086090522, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,112] Trial 14 finished with value: 0.6435331230283912 and parameters: {'alpha': 0.010214241140468941, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,123] Trial 15 finished with value: 0.6421568627450981 and parameters: {'alpha': 0.0024857463600170947, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,133] Trial 16 finished with value: 0.6278735632183908 and parameters: {'alpha': 0.14604213237650276, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,144] Trial 17 finished with value: 0.6401590457256461 and parameters: {'alpha': 0.039887715154137734, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,154] Trial 18 finished with value: 0.0915032679738562 and parameters: {'alpha': 9.599976813700536, 'fit_prior': True}. Best is trial 0 with value: 0.6450809464508095.\n",
      "[I 2025-12-22 10:38:30,164] Trial 19 finished with value: 0.645320197044335 and parameters: {'alpha': 0.003655769570495071, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,174] Trial 20 finished with value: 0.6406345332519829 and parameters: {'alpha': 0.0018183937038552707, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,182] Trial 21 finished with value: 0.6444032158317873 and parameters: {'alpha': 0.004899928640232312, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,194] Trial 22 finished with value: 0.645320197044335 and parameters: {'alpha': 0.0037344763354986493, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,203] Trial 23 finished with value: 0.6452028332260141 and parameters: {'alpha': 0.020063476696809378, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,214] Trial 24 finished with value: 0.6432225063938619 and parameters: {'alpha': 0.016972620631346576, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,224] Trial 25 finished with value: 0.6434558349451966 and parameters: {'alpha': 0.021356728387157017, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,234] Trial 26 finished with value: 0.6441087613293052 and parameters: {'alpha': 0.0010424430029171718, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,246] Trial 27 finished with value: 0.644963144963145 and parameters: {'alpha': 0.0032025579327939688, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,257] Trial 28 finished with value: 0.6414835164835165 and parameters: {'alpha': 0.07781509642529642, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,266] Trial 29 finished with value: 0.6447613143211407 and parameters: {'alpha': 0.005896445459912624, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,277] Trial 30 finished with value: 0.6444444444444445 and parameters: {'alpha': 0.00427467062765429, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,286] Trial 31 finished with value: 0.6420382165605095 and parameters: {'alpha': 0.01549911143858416, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,297] Trial 32 finished with value: 0.6422912858013407 and parameters: {'alpha': 0.0015895612283297227, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,307] Trial 33 finished with value: 0.6425855513307985 and parameters: {'alpha': 0.011500228446101496, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,316] Trial 34 finished with value: 0.6434558349451966 and parameters: {'alpha': 0.020644188001732993, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,327] Trial 35 finished with value: 0.6449230769230769 and parameters: {'alpha': 0.0035033148177670615, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,346] Trial 36 finished with value: 0.6341463414634146 and parameters: {'alpha': 0.00816871616599642, 'fit_prior': False}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,356] Trial 37 finished with value: 0.6422912858013407 and parameters: {'alpha': 0.0017317610217565077, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,367] Trial 38 finished with value: 0.6381007527504343 and parameters: {'alpha': 0.04869010406905912, 'fit_prior': False}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,377] Trial 39 finished with value: 0.6343885785226567 and parameters: {'alpha': 0.33838945713145585, 'fit_prior': False}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,389] Trial 40 finished with value: 0.642903434867142 and parameters: {'alpha': 0.02473209504844617, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,398] Trial 41 finished with value: 0.6445672191528545 and parameters: {'alpha': 0.0030699773272363233, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,409] Trial 42 finished with value: 0.6444032158317873 and parameters: {'alpha': 0.004915082695989991, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,418] Trial 43 finished with value: 0.6414172266340867 and parameters: {'alpha': 0.0021732502579554632, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,428] Trial 44 finished with value: 0.6425855513307985 and parameters: {'alpha': 0.01176244621079754, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,440] Trial 45 finished with value: 0.6433915211970075 and parameters: {'alpha': 0.00716184953409217, 'fit_prior': True}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,449] Trial 46 finished with value: 0.6326987681970885 and parameters: {'alpha': 0.001377006831448997, 'fit_prior': False}. Best is trial 19 with value: 0.645320197044335.\n",
      "[I 2025-12-22 10:38:30,464] Trial 47 finished with value: 0.645359557467732 and parameters: {'alpha': 0.0033857817135395417, 'fit_prior': True}. Best is trial 47 with value: 0.645359557467732.\n",
      "[I 2025-12-22 10:38:30,474] Trial 48 finished with value: 0.6444032158317873 and parameters: {'alpha': 0.004829664689274682, 'fit_prior': True}. Best is trial 47 with value: 0.645359557467732.\n",
      "[I 2025-12-22 10:38:30,485] Trial 49 finished with value: 0.6443883984867591 and parameters: {'alpha': 0.009694198026936182, 'fit_prior': True}. Best is trial 47 with value: 0.645359557467732.\n"
     ]
    }
   ],
   "source": [
    "def multinomial_nb_objective(trial):\n",
    "    params = dict(\n",
    "        alpha=trial.suggest_float('alpha', 1e-3, 10, log=True),\n",
    "        fit_prior=trial.suggest_categorical('fit_prior', [True, False])\n",
    "    )\n",
    "    \n",
    "    clf = (MultinomialNB(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "nb_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "nb_study.optimize(multinomial_nb_objective, n_trials=50, callbacks=[callback])\n",
    "\n",
    "nb_model = nb_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f06a7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB with Best Hyperparameters F1-scores:\n",
      "train: 0.9828919288030509\n",
      "val:   0.7011037146799258\n",
      "val:                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.71      0.76      1271\n",
      "           1       0.58      0.72      0.65       729\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.70      0.71      0.70      2000\n",
      "weighted avg       0.73      0.71      0.72      2000\n",
      "\n",
      "test:  0.7014607973041501\n",
      "test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.67      0.75       636\n",
      "           1       0.57      0.77      0.66       364\n",
      "\n",
      "    accuracy                           0.71      1000\n",
      "   macro avg       0.70      0.72      0.70      1000\n",
      "weighted avg       0.74      0.71      0.71      1000\n",
      "\n",
      "{'alpha': 0.0033857817135395417, 'class_prior': None, 'fit_prior': True, 'force_alpha': True}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'alpha': 0.0033857817135395417, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "print(\"MultinomialNB with Best Hyperparameters F1-scores:\")\n",
    "print('train:', f1_score(y_train, nb_model.predict(X_train_tfidf), average='macro'))\n",
    "print('val:  ', f1_score(y_val  , nb_model.predict(X_val_tfidf), average='macro'))\n",
    "print('val:  ', classification_report(y_val  , nb_model.predict(X_val_tfidf)))\n",
    "print('test: ', f1_score(y_test , nb_model.predict(X_test_tfidf), average='macro'))\n",
    "print('test: ', classification_report(y_test , nb_model.predict(X_test_tfidf)))\n",
    "\n",
    "print(nb_model.get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(nb_study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbafb0",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b758f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4599109c",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "998deaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-22 10:39:24,104] A new study created in memory with name: no-name-d7e6092e-22d4-4779-b807-35a215f72720\n",
      "[I 2025-12-22 10:39:24,442] Trial 0 finished with value: 0.7070967741935484 and parameters: {'n_estimators': 81, 'max_depth': 53, 'min_samples_split': 7, 'min_samples_leaf': 9, 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.7070967741935484.\n",
      "[I 2025-12-22 10:39:25,431] Trial 1 finished with value: 0.6836734693877551 and parameters: {'n_estimators': 154, 'max_depth': 30, 'min_samples_split': 13, 'min_samples_leaf': 1, 'class_weight': 'balanced_subsample'}. Best is trial 0 with value: 0.7070967741935484.\n",
      "[I 2025-12-22 10:39:25,631] Trial 2 finished with value: 0.2823803967327888 and parameters: {'n_estimators': 78, 'max_depth': 10, 'min_samples_split': 12, 'min_samples_leaf': 10, 'class_weight': None}. Best is trial 0 with value: 0.7070967741935484.\n",
      "[I 2025-12-22 10:39:26,327] Trial 3 finished with value: 0.716514954486346 and parameters: {'n_estimators': 153, 'max_depth': 45, 'min_samples_split': 10, 'min_samples_leaf': 5, 'class_weight': 'balanced_subsample'}. Best is trial 3 with value: 0.716514954486346.\n",
      "[I 2025-12-22 10:39:26,843] Trial 4 finished with value: 0.5310410697230181 and parameters: {'n_estimators': 189, 'max_depth': 99, 'min_samples_split': 11, 'min_samples_leaf': 8, 'class_weight': None}. Best is trial 3 with value: 0.716514954486346.\n",
      "[I 2025-12-22 10:39:27,492] Trial 5 finished with value: 0.7200512491992312 and parameters: {'n_estimators': 162, 'max_depth': 56, 'min_samples_split': 3, 'min_samples_leaf': 5, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.7200512491992312.\n",
      "[I 2025-12-22 10:39:27,829] Trial 6 finished with value: 0.6920980926430518 and parameters: {'n_estimators': 116, 'max_depth': 18, 'min_samples_split': 2, 'min_samples_leaf': 7, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.7200512491992312.\n",
      "[I 2025-12-22 10:39:28,299] Trial 7 finished with value: 0.699867197875166 and parameters: {'n_estimators': 121, 'max_depth': 27, 'min_samples_split': 12, 'min_samples_leaf': 7, 'class_weight': 'balanced_subsample'}. Best is trial 5 with value: 0.7200512491992312.\n",
      "[I 2025-12-22 10:39:28,578] Trial 8 finished with value: 0.6981519507186859 and parameters: {'n_estimators': 83, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 4, 'class_weight': 'balanced'}. Best is trial 5 with value: 0.7200512491992312.\n",
      "[I 2025-12-22 10:39:28,973] Trial 9 finished with value: 0.7093908629441624 and parameters: {'n_estimators': 83, 'max_depth': 77, 'min_samples_split': 13, 'min_samples_leaf': 8, 'class_weight': 'balanced_subsample'}. Best is trial 5 with value: 0.7200512491992312.\n"
     ]
    }
   ],
   "source": [
    "def rf_objective(trial):\n",
    "    params = dict(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 200),\n",
    "        max_depth=trial.suggest_int('max_depth', 10, 100),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 15),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        class_weight=trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample', None]),\n",
    "        n_jobs=-1, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    clf = (RandomForestClassifier(**params))\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    trial.set_user_attr(key=\"model\", value=clf)\n",
    "\n",
    "    y_pred = clf.predict(X_val_tfidf)\n",
    "    return f1_score(y_val, y_pred)\n",
    "\n",
    "sampler = TPESampler(seed=22)\n",
    "rf_study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "rf_study.optimize(rf_objective, n_trials=10, callbacks=[callback])\n",
    "\n",
    "rf_model = rf_study.user_attrs['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6458ff02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier with Best Hyperparameters F1-scores:\n",
      "train: 0.8093801326459344\n",
      "val:   0.770439728740657\n",
      "val:                 precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.82      1271\n",
      "           1       0.68      0.77      0.72       729\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.77      0.78      0.77      2000\n",
      "weighted avg       0.79      0.78      0.78      2000\n",
      "\n",
      "test:  0.7900017865519651\n",
      "test:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83       636\n",
      "           1       0.69      0.81      0.75       364\n",
      "\n",
      "    accuracy                           0.80      1000\n",
      "   macro avg       0.79      0.80      0.79      1000\n",
      "weighted avg       0.81      0.80      0.80      1000\n",
      "\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'gini', 'max_depth': 56, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 5, 'min_samples_split': 3, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 162, 'n_jobs': -1, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Best hyperparameters:\n",
      "{'n_estimators': 162, 'max_depth': 56, 'min_samples_split': 3, 'min_samples_leaf': 5, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForestClassifier with Best Hyperparameters F1-scores:\")\n",
    "print('train:', f1_score(y_train, rf_model.predict(X_train_tfidf), average='macro'))\n",
    "print('val:  ', f1_score(y_val  , rf_model.predict(X_val_tfidf), average='macro'))\n",
    "print('val:  ', classification_report(y_val  , rf_model.predict(X_val_tfidf)))\n",
    "print('test: ', f1_score(y_test , rf_model.predict(X_test_tfidf), average='macro'))\n",
    "print('test: ', classification_report(y_test , rf_model.predict(X_test_tfidf)))\n",
    "\n",
    "print(rf_model.get_params())\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(rf_study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
