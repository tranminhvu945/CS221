import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import AutoModel, AutoTokenizer
from captum.attr import LayerIntegratedGradients
import torch.nn.functional as F
from processors.vietnamese_processor import VietnameseTextPreprocessor 

class PhoBertSentiment(nn.Module):
    def __init__(self):
        super(PhoBertSentiment, self).__init__()
        # Kh·ªüi t·∫°o gi·ªëng h·ªát l√∫c train
        self.phobert = AutoModel.from_pretrained("vinai/phobert-base")
        self.dropout = nn.Dropout(0.1)
        
        # QUAN TR·ªåNG: ƒê·ªïi t√™n th√†nh classifier ƒë·ªÉ kh·ªõp v·ªõi file .pth
        self.classifier = nn.Linear(768, 2) 

    def forward(self, input_ids, attention_mask):
        # Logic Forward gi·ªëng h·ªát l√∫c train
        outputs = self.phobert(
            input_ids=input_ids,
            attention_mask=attention_mask
        )
        
        # L·∫•y pooler_output (CLS token ƒë√£ qua x·ª≠ l√Ω)
        pooled_output = outputs.pooler_output
        x = self.dropout(pooled_output)
        logits = self.classifier(x)
        return logits

@st.cache_resource
def load_all_resources():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # 1. Load Preprocessor
    preprocessor = VietnameseTextPreprocessor(vncorenlp_dir='./processors/VnCoreNLP')
    
    # 2. Load Tokenizer
    tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base")
    
    # 3. Load Model
    model = PhoBertSentiment()
    
    # Load weights (ƒë√£ th√™m weights_only=True ƒë·ªÉ t·∫Øt c·∫£nh b√°o)
    try:
        model.load_state_dict(torch.load("phobert_best_model.pth", map_location=device, weights_only=True))
    except RuntimeError as e:
        # Fallback n·∫øu model c≈© l∆∞u c·∫£ ki·∫øn tr√∫c
        st.warning(f"ƒêang th·ª≠ load ch·∫ø ƒë·ªô c≈© do l·ªói: {e}")
        model.load_state_dict(torch.load("phobert_best_model.pth", map_location=device, weights_only=False))
      
    model.to(device)
    model.eval()
    
    return preprocessor, tokenizer, model, device

# ==========================================
# 2. H√ÄM GI·∫¢I TH√çCH (CAPTUM)
# ==========================================
def visualize_explanation(text, true_label, model, tokenizer, device):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    input_ids = inputs['input_ids'].to(device)
    attention_mask = inputs['attention_mask'].to(device)

    with torch.no_grad():
        outputs = model(input_ids, attention_mask)
        probs = F.softmax(outputs, dim=1)
        confidence, pred_label_idx = torch.max(probs, 1)
        pred_label = pred_label_idx.item()
        conf_score = confidence.item()

    def forward_wrapper(inp, mask):
        return model(inp, mask)

    lig = LayerIntegratedGradients(forward_wrapper, model.phobert.embeddings)
    
    attributions, delta = lig.attribute(
        inputs=input_ids,
        additional_forward_args=(attention_mask,),
        baselines=torch.zeros_like(input_ids),
        target=pred_label,
        return_convergence_delta=True,
        n_steps=50
    )

    attributions_sum = attributions.sum(dim=2).squeeze(0)
    attributions_sum = attributions_sum / torch.norm(attributions_sum)
    attr_score = attributions_sum.cpu().detach().numpy()
    
    raw_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])
    tokens = [t.replace('_', ' ') for t in raw_tokens]

    real_len = len([t for t in raw_tokens if t != '<pad>'])
    attr_score = attr_score[:real_len]
    tokens = tokens[:real_len]

    fig, ax = plt.subplots(figsize=(20, 4))
    sns.heatmap(attr_score.reshape(1, -1), cmap='RdYlGn', center=0, 
                annot=False, cbar=True, cbar_kws={'label': 'T·∫ßm quan tr·ªçng'}, ax=ax)
    ax.set_xticks(np.arange(len(tokens)) + 0.5)
    ax.set_xticklabels(tokens, rotation=45, ha='right', fontsize=12)
    ax.set_yticks([])
    
    label_map = {0: "Non-Constructive", 1: "Constructive"}
    pred_text = label_map[pred_label]
    true_text = label_map[true_label]
    
    if pred_label == true_label:
        status = "CORRECT"
        color = "green"
    else:
        status = "WRONG"
        color = "red"
        
    ax.set_title(f"True: {true_text} | Pred: {pred_text} | {status}", 
                 fontsize=14, fontweight='bold', color=color)
    plt.tight_layout()
    return fig, pred_label, conf_score

# ==========================================
# 3. GIAO DI·ªÜN STREAMLIT
# ==========================================

st.set_page_config(page_title="ViCTSD Analyzer", layout="wide")
st.title("üõ°Ô∏è ViCTSD: Ph√¢n lo·∫°i b√¨nh lu·∫≠n mang t√≠nh x√¢y d·ª±ng")

try:
    preprocessor, tokenizer, model, device = load_all_resources()
    st.toast("‚úÖ ƒê√£ t·∫£i Model & VnCoreNLP th√†nh c√¥ng!", icon="üöÄ")
except Exception as e:
    st.error(f"L·ªói kh·ªüi t·∫°o: {e}")
    st.info("Vui l√≤ng ki·ªÉm tra xem th∆∞ m·ª•c 'VnCoreNLP' ƒë√£ c√≥ ƒë·ªß file .jar ch∆∞a.")
    st.stop()

# Layout Input
col_input, col_label = st.columns([3, 1])

with col_input:
    raw_text = st.text_area("Nh·∫≠p vƒÉn b·∫£n:", height=120)

with col_label:
    st.write("### Ground Truth")
    label_option = st.radio(
        "Ch·ªçn nh√£n th·ª±c t·∫ø:", 
        ("Non-Constructive (0)", "Constructive (1)"),
        index=0,
        label_visibility="collapsed" 
    )
    true_label_idx = 1 if "Constructive (1)" in label_option else 0

if st.button("üöÄ B·∫Øt ƒë·∫ßu d·ª± ƒëo√°n v√† ph√¢n t√≠ch", type="primary"):
    if not raw_text.strip():
        st.warning("Vui l√≤ng nh·∫≠p n·ªôi dung.")
    else:
        # --- B∆Ø·ªöC 1: TI·ªÄN X·ª¨ L√ù ---
        with st.status("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...", expanded=True) as status:
            clean_text = preprocessor.process_text(raw_text)
            status.update(label="Ti·ªÅn x·ª≠ l√Ω ho√†n t·∫•t!", state="complete", expanded=False)

        # Hi·ªÉn th·ªã so s√°nh Before/After
        st.subheader("1Ô∏è‚É£ K·∫øt qu·∫£ Ti·ªÅn x·ª≠ l√Ω")
        c1, c2 = st.columns(2)
        with c1:
            st.text_area("VƒÉn b·∫£n g·ªëc", raw_text, height=130, disabled=True)
        with c2:
            st.text_area("VƒÉn b·∫£n ƒë√£ ti·ªÅn x·ª≠ l√Ω", clean_text, height=130, disabled=True)

        st.subheader("2Ô∏è‚É£ K·∫øt qu·∫£ d·ª± ƒëo√°n & Gi·∫£i th√≠ch")
        try:
            fig, pred, conf = visualize_explanation(clean_text, true_label_idx, model, tokenizer, device)
            
            # --- HI·ªÇN TH·ªä K·∫æT QU·∫¢ ---
            with st.container(border=True):
                # Chia 4 c·ªôt
                c1, c2, c3, c4 = st.columns([1.2, 1.2, 0.8, 1])
                
                label_map = {0: "Non-Constructive", 1: "Constructive"}
                true_txt = label_map[true_label_idx]
                pred_txt = label_map[pred]
                
                # C·ªòT 1: Nh√£n Th·ª±c T·∫ø
                with c1:
                    st.metric(label="üè∑Ô∏è Nh√£n Th·ª±c T·∫ø", value=true_txt)

                # C·ªòT 2: Nh√£n D·ª± ƒêo√°n
                with c2:
                    st.metric(label="ü§ñ Nh√£n D·ª± ƒêo√°n", value=pred_txt)

                # C·ªòT 3: Tr·∫°ng Th√°i
                with c3:
                    if pred == true_label_idx:
                        # delta_color="normal" (m√†u xanh) cho ƒë√∫ng
                        st.metric(label="Tr·∫°ng th√°i", value="Correct", delta="Ch√≠nh x√°c", delta_color="normal")
                    else:
                        # delta_color="inverse" (m√†u ƒë·ªè) cho sai
                        st.metric(label="Tr·∫°ng th√°i", value="Wrong", delta="Nh·∫ßm l·∫´n", delta_color="inverse")
                
                # C·ªòT 4: ƒê·ªô Tin C·∫≠y
                with c4:
                    st.metric(label="üìä ƒê·ªô Tin C·∫≠y", value=f"{conf:.2%}")

            # Heatmap
            st.write("**Heatmap t·∫ßm quan tr·ªçng c·ªßa token:**")
            st.pyplot(fig)
            
        except Exception as e:
            st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")